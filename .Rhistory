semi_join(voc, by = c("ngram"="word"))
#decreases the voc size
voc <- tibble(word = unique(unigram$ngram))
sum(voc$word=="i'd")
sum(contract$word=="i'd")
contract
View(contract)
contract %>% str_to_lower()
contract <- contract %>% str_to_lower()
prof <- read_lines("~/R/Capestone/data/facebook-bad-words-list_comma-separated-text-file_2021_01_18.txt")[15]
prof <- prof %>% str_split(", ") %>% flatten %>% unlist
prof <- tibble("word" = prof)
english <- read_lines("~/R/Capestone/data/diction.txt")
english <- tibble("word" = english[!english==""])
contract <- read_lines("~/R/Capestone/data/contractions.txt")
contract <- tibble("word" = contract)
contract %>% unnest_tokens(word, word)
prof <- read_lines("~/R/Capestone/data/facebook-bad-words-list_comma-separated-text-file_2021_01_18.txt")[15]
prof <- prof %>% str_split(", ") %>% flatten %>% unlist
prof <- tibble("word" = prof)
english <- read_lines("~/R/Capestone/data/diction.txt")
english <- tibble("word" = english[!english==""])
contract <- read_lines("~/R/Capestone/data/contractions.txt")
contract <- tibble("word" = contract) %>% unnest_tokens(word,word)
contract
#clean up ram
rm(blog,news,twitter)
voc <- bind_rows(english, contract) %>% anti_join(prof)
unigram <- corpus %>% unnest_tokens(ngram, text, token = "ngrams", n = 1) %>%
semi_join(voc, by = c("ngram"="word"))
#decreases the voc size
voc <- tibble(word = unique(unigram$ngram))
sum(voc$word=="i'd")
#OOV 1% of the least likely unigrams
unigramcount <- unigram %>% count(ngram)
unk <- unigramcount %>%
filter(n==1) %>%
slice_sample(prop = 0.005)
unigram[unigram$ngram %in% unk$ngram,]$ngram <- "<unk>"
unigram <- unigram %>%
filter(!n==1)
#clean up ram
rm(blog,news,twitter)
voc <- bind_rows(english, contract) %>% anti_join(prof)
unigram <- corpus %>% unnest_tokens(ngram, text, token = "ngrams", n = 1) %>%
semi_join(voc, by = c("ngram"="word"))
#decreases the voc size
voc <- tibble(word = unique(unigram$ngram))
#OOV 1% of the least likely unigrams
unigramcount <- unigram %>% count(ngram)
unk <- unigramcount %>%
filter(n==1) %>%
slice_sample(prop = 0.005)
unigram[unigram$ngram %in% unk$ngram,]$ngram <- "<unk>"
unigram <- unigram %>%
count(ngram) %>%
filter(!n==1)
voc <- tibble(word = unique(unigram$ngram))
sum(voc$word=="i'd")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = TRUE)
library(tidyverse)
library(tidytext)
library(pryr)
#downloads the corpus files, profanity filter and English dictionary
url <- "https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip"
url2 <- "https://www.freewebheaders.com/download/files/facebook-bad-words-list_comma-separated-text-file_2021_01_18.zip"
url3 <- "https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt"
url4 <- "https://raw.githubusercontent.com/mark-edney/Capestone/1c143b40dd71f0564c3248df2a8638d08af10440/data/contractions.txt"
if(dir.exists("~/R/Capestone/data/") == FALSE){
dir.create("~/R/Capestone/data/")}
if(file.exists("~/R/Capestone/data/data.zip") == FALSE|
file.exists("~/R/Capestone/data/prof.zip")==FALSE|
file.exists("~/R/Capestone/data/diction.txt")==FALSE|
file.exists("~/R/Capestone/data/contractions.txt")==FALSE){
download.file(url,destfile = "~/R/Capestone/data/data.zip")
download.file(url2,destfile = "~/R/Capestone/data/prof.zip")
download.file(url3,destfile = "~/R/Capestone/data/diction.txt")
download.file(url4,destfile = "~/R/Capestone/data/contractions.txt")
setwd("~/R/Capestone/data/")
unzip("~/R/Capestone/data/prof.zip")
unzip("~/R/Capestone/data/data.zip")
setwd("~/R/Capestone")
}
blog <- read_lines("~/R/Capestone/data/final/en_US/en_US.blogs.txt")
news <- read_lines("~/R/Capestone/data/final/en_US/en_US.news.txt")
twitter <- read_lines("~/R/Capestone/data/final/en_US/en_US.twitter.txt")
blog <- tibble(text = blog)
news <- tibble(text = news)
twitter <- tibble(text = twitter)
set.seed(90210)
corpus <- bind_rows(blog,twitter,news) %>%
slice_sample(prop = 0.05) %>%
mutate(line = row_number())
prof <- read_lines("~/R/Capestone/data/facebook-bad-words-list_comma-separated-text-file_2021_01_18.txt")[15]
prof <- prof %>% str_split(", ") %>% flatten %>% unlist
prof <- tibble("word" = prof)
english <- read_lines("~/R/Capestone/data/diction.txt")
english <- tibble("word" = english[!english==""])
contract <- read_lines("~/R/Capestone/data/contractions.txt")
contract <- tibble("word" = contract) %>% unnest_tokens(word,word)
#clean up ram
rm(blog,news,twitter)
voc <- bind_rows(english, contract) %>% anti_join(prof)
unigram <- corpus %>% unnest_tokens(ngram, text, token = "ngrams", n = 1) %>%
semi_join(voc, by = c("ngram"="word"))
#decreases the voc size
voc <- tibble(word = unique(unigram$ngram))
#OOV 1% of the least likely unigrams
unigramcount <- unigram %>% count(ngram)
unk <- unigramcount %>%
filter(n==1) %>%
slice_sample(prop = 0.005)
unigram[unigram$ngram %in% unk$ngram,]$ngram <- "<unk>"
unigram <- unigram %>%
count(ngram) %>%
filter(!n==1)
voc <- tibble(word = unique(unigram$ngram))
corpus <- unigram %>%
group_by(line) %>%
summarise(line = paste(ngram, collapse = " ")) %>%
rename("text" = "line") %>%
mutate("line" = row_number())
unlink('Capestone/Main_notebook_cache', recursive = TRUE)
shiny::runApp('Capestone/Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
shiny::runApp('Capestone/Shiny App/Capestone')
runApp()
runApp('Capestone/Shiny App/Capestone')
runApp('Capestone/Shiny App/Capestone')
library(shiny)
library(tidyverse)
library(tidytext)
library(pryr)
setwd("~/R/Capestone")
ngrams <- readRDS("ngrams.rds")
ngrams$two$bin <- substr(ngrams$two$word2,1,1)
ngrams$twp$bin[ngrams$one$bin=="<"] <- "<unk>"
voc <- tibble(word = ngrams$one$ngram)
maxn <- length(ngrams)-1
dist <- tibble(word=voc)
input <- tibble(text = "this is just the test") %>% unnest_tokens(word,text, token = "ngrams", n=1)
input[!input$word %in% voc$word, ] <- "unk"
truetext <- input
runApp('Shiny App/Capestone')
ngrams.tbl <- ngrams[[2:n]]
ngrams.tbl <- ngrams[2:n]
ngrams[2:n]
ngrams[2]
ngrams[2:3]
ngrams[2:6]
ngrams.tbl
ngrams.tbl <- ngrams[[2:6]]
ngrams.tbl <- ngrams[2:6]
ngrams.tbl
ngrams.tbl[]
ngrams.tbl[[]]
ngrams.tbl[
]
length(ngrams.tbl)
length(ngrams.tbl[])
length(ngrams.tbl %>% unlist)
ngrams.tbl %>% flatten()
ngrams.tbl <- ngrams[2:n]
n <- 6
ngrams.tbl <- ngrams[2:n]
for (i in 2:n){
ngrams.tbl[i] %>% filter(.[,i] == input$word[i])
}
n<-2
for (i in 2:n){
ngrams.tbl[i] %>% filter(.[,i] == input$word[i])
}
ngrams.tbl[2]
ngrams.tbl[2] %>% filter(.[,2] == input$word[2])
ngrams.tbl[[2]] %>% filter(.[,2] == input$word[2])
ngrams.tbl <- ngrams[2:n]
for (i in 2:n){
ngrams.tbl[[i]] %>% filter(.[,i] == input$word[i])
}
input
for (i in 2:n){
ngrams.tbl[[length(text)-i]] %>% filter(.[,i] == input$word[i])
}
for (i in 2:n){
ngrams.tbl[[length(text)-2]] %>% filter(.[,2] == input$word[2])
}
ngrams.tbl[[length(text)-2]] %>% filter(.[,2] == input$word[2])
ngrams.tbl[[2]] %>% filter(.[,2] == input$word[2])
input$word
input$word[2]
input$word[length(input)]
input$word[nrow(input)]
ngrams.tbl[[2]] %>% filter(.[,2] == input$word[nrow(input)])
ngrams.tbl[[2]]
ngrams.tbl[2]
ngrams.tbl
ngrams.tbl <- ngrams
ngrams.tbl[[2]]
ngrams.tbl[[2]] %>% filter(.[,2] == input$word[nrow(input)])
ngrams.tbl[[2]] %>% filter(.[,1] == input$word[nrow(input)])
ngrams
ngrams <- readRDS("ngrams.rds")
ngrams.tbl <- ngrams
ngrams.tbl[[2]] %>% filter(.[,1] == input$word[nrow(input)])
ngrams.tbl[[2]] %>% filter(.[,1] == input$word[nrow(input)])
ngrams.tbl[[3]] %>% filter(.[,1] == input$word[nrow(input)])
ngrams.tbl[[3]] %>% filter(.[,i-1] == input$word[nrow(input)])
for (i in 2:n){
ngrams.tbl[[i]] %>% filter(.[,i-1] == input$word[nrow(input)])
}
for (i in 2:n){
ngrams.tbl[[i]] %>% filter(.[,i-1] == input$word[nrow(input)])
}
ngrams.tbl[[i]] %>% filter(.[,i-1] == input$word[nrow(input)])
i<- 3
ngrams.tbl[[i]] %>% filter(.[,i-1] == input$word[nrow(input)])
ngrams.tbl[[i]] %>% filter(.[,i-1] == input$word[nrow(input)])
i <- 4
ngrams.tbl[[i]] %>% filter(.[,i-1] == input$word[nrow(input)])
ngrams.tbl[[i]] %>% filter(.[,i-1] == input$word[nrow(input)])
i <- 5
ngrams.tbl[[i]] %>% filter(.[,i-1] == input$word[nrow(input)])
setwd("~/R/Capestone")
corpus <- readRDS("corpus10.rds")
ngrams$four
tetragram <- readRDS("tetragram10.rds") %>% filter(n>quantile(.$n, 0.75))
tetragram
setwd("~/R/Capestone")
corpus <- readRDS("corpus10.rds")
unigram <- readRDS("unigram10.rds")
bigram <- readRDS("bigram10.rds") %>% filter(n>quantile(.$n, 0.75))
trigram <- readRDS("trigram10.rds") %>% filter(n>quantile(.$n, 0.75))
tetragram <- readRDS("tetragram10.rds") %>% filter(n>quantile(.$n, 0.75))
pentagram <- readRDS("pentagram10.rds") %>% filter(n>quantile(.$n, 0.75))
hexagram <- readRDS("hexagram10.rds") %>% filter(n>quantile(.$n, 0.75))
ngrams <- list("one" = unigram, "two" = bigram, "three" =trigram,
"four" = tetragram, "five" = pentagram, "six" = hexagram)
ngrams
saveRDS(ngrams, "ngrams.rds")
ngrams <- readRDS("ngrams.rds")
ngrams.tbl <- ngrams
ngrams.tbl[[i]] %>% filter(.[,i-1] == input$word[nrow(input)])
i<- 6
ngrams.tbl[[i]] %>% filter(.[,i-1] == input$word[nrow(input)])
if(i>2){
ngrams.tbl[[i]] %>% filter(.[,i-2] == input$word[nrow(input)-1])
}
ngrams.tbl[[i]] %>% filter(.[,i-1] == input$word[nrow(input)])
i
i
if(i>2){
ngrams.tbl[[i]] %>% filter(.[,i-2] == input$word[nrow(input)-1])
}
ngrams.tbl[[i]] %>% filter(.[,i-1] == input$word[nrow(input)])
ngrams.tbl[[i]] %>% filter(.[,i-2] == input$word[nrow(input)-1])
ngrams.tbl[[i]] %>% filter(.[,i-2] == input$word[nrow(input)-1]) %>% filter(.[,i-1] == input$word[nrow(input)])
for (i in 2:n){
if(i>5){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-4] == input$word[nrow(input)-3])
}
if(i>4){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-4] == input$word[nrow(input)-3])
}
if(i>3){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-3] == input$word[nrow(input)-2])
}
if(i>2){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-2] == input$word[nrow(input)-1])
}
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-1] == input$word[nrow(input)])
}
ngrams.tbl
n
n<- 6
ngrams.tbl <- ngrams[2:n]
ngrams.tbl
for (i in 2:n){
if(i>5){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-4] == input$word[nrow(input)-3])
}
if(i>4){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-4] == input$word[nrow(input)-3])
}
if(i>3){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-3] == input$word[nrow(input)-2])
}
if(i>2){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-2] == input$word[nrow(input)-1])
}
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-1] == input$word[nrow(input)])
}
n <- 4
ngrams.tbl <- ngrams[2:n]
for (i in 2:n){
if(i>5){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-4] == input$word[nrow(input)-3])
}
if(i>4){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-4] == input$word[nrow(input)-3])
}
if(i>3){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-3] == input$word[nrow(input)-2])
}
if(i>2){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-2] == input$word[nrow(input)-1])
}
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-1] == input$word[nrow(input)])
}
n<- 6
ngrams.tbl <- ngrams[2:n]
for (i in 2:n-1){
if(i>5){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-4] == input$word[nrow(input)-3])
}
if(i>4){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-4] == input$word[nrow(input)-3])
}
if(i>3){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-3] == input$word[nrow(input)-2])
}
if(i>2){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-2] == input$word[nrow(input)-1])
}
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-1] == input$word[nrow(input)])
}
ngrams.tbl
input
ngrams.tbl <- ngrams[2:n]
for (i in 2:n-1){
if(i>5){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-5] == input$word[nrow(input)-4])
}
if(i>4){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-4] == input$word[nrow(input)-3])
}
if(i>3){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-3] == input$word[nrow(input)-2])
}
if(i>2){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-2] == input$word[nrow(input)-1])
}
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-1] == input$word[nrow(input)])
}
ngrams.tbl
ngrams.tbl[[2]] %>% filter(.[,2-1] == input$word[nrow(input)])
runApp('Shiny App/Capestone')
ngrams.tbl <- ngrams[1:n]
for (i in 2:n-1){
if(i>5){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-5] == input$word[nrow(input)-4])
}
if(i>4){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-4] == input$word[nrow(input)-3])
}
if(i>3){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-3] == input$word[nrow(input)-2])
}
if(i>2){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-2] == input$word[nrow(input)-1])
}
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-1] == input$word[nrow(input)])
}
ngrams.tbl
ngrams.tbl <- ngrams[1:n]
for (i in 2:n){
if(i>5){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-5] == input$word[nrow(input)-4])
}
if(i>4){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-4] == input$word[nrow(input)-3])
}
if(i>3){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-3] == input$word[nrow(input)-2])
}
if(i>2){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-2] == input$word[nrow(input)-1])
}
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-1] == input$word[nrow(input)])
}
ngrams.tbl
ngrams.tbl <- ngrams[1:n]
for (i in 2:n){
if(i>5){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-5] == input$word[nrow(input)-4])
}
if(i>4){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-4] == input$word[nrow(input)-3])
}
if(i>3){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-3] == input$word[nrow(input)-2])
}
if(i>2){
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-2] == input$word[nrow(input)-1])
}
ngrams.tbl[[i]] <- ngrams.tbl[[i]] %>%
filter(.[,i-1] == input$word[nrow(input)]) %>%
arrange(desc(n))
}
ngrams.tbl
ngrams.tbl
length(ngrams.tbl)
nrow(ngrams.tbl[[i]])>0
nrow(ngrams.tbl[[1]])>0
nrow(ngrams.tbl[[2]])>0
nrow(ngrams.tbl[[3]])>0
nrow(ngrams.tbl[[4]])>0
maxval <- sum(nrow(ngrams.tbl[[1:n]])>0)
maxval <- sum(nrow(ngrams.tbl[1:n])>0)
maxval
ngrams.tbl[1:n]
nrow(ngrams.tbl[1:n])
map(ngrams.tbl[1:n], nrow)
nrow(ngrams.tbl[1:n]>0)
map(ngrams.tbl[1:n], nrow>0)
map(ngrams.tbl[1:n], nrow)>0
maxval <- sum(map(ngrams.tbl[1:n], nrow)>0)
maxval
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
setwd("~/R/Capestone")
ngrams <- readRDS("ngrams.rds")
runApp('Shiny App/Capestone')
View(ngrams)
ngrams$six
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp()
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp()
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
runApp('Shiny App/Capestone')
